{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1344508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "pos_files = [f for f in listdir(\"movies_reviews/pos\")]\n",
    "neg_files = [f for f in listdir(\"movies_reviews/neg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9276c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rev = []    \n",
    "neg_rev = []\n",
    "for file in pos_files:\n",
    "    name = \"movies_reviews/pos/\" + file\n",
    "    with open(name, \"r\") as f:\n",
    "        contant = f.read()\n",
    "        pos_rev.append(contant)\n",
    "\n",
    "for file in neg_files:\n",
    "    name = \"movies_reviews/neg/\" + file\n",
    "    with open(name, \"r\") as f:\n",
    "        contant = f.read()\n",
    "        neg_rev.append(contant)\n",
    "rev = pos_rev + neg_rev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe4df1",
   "metadata": {},
   "source": [
    "In the next cell I use TfidfVectorizer which uses term frequancy - inverse document frequancy. In simple terms this is the number of times a word is contained ina specific text, vs how many times the word is contained in all the text. This gives us an idea of how important a certain word is to a specific text.  So for example stop words, that will be frequant in every text, will get a low score as they are not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcd4d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Tvec = TfidfVectorizer()\n",
    "vec = Tvec.fit_transform(rev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f35a28e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At position 3 should be a cat: 1.0\n",
      "At position 1002 should be a dog: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2005,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pos_lable = np.ones((len(pos_rev),)) \n",
    "lables = np.concatenate((pos_lable, np.zeros((len(neg_rev),))))\n",
    "lables = lables.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "376696f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(vec, lables, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f33c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c98ccc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8208955223880597\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy\", accuracy_score(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9007f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [f for f in listdir(\"movies_reviews/new_reviews\")]\n",
    "new_rev = []    \n",
    "\n",
    "for file in test_files:\n",
    "    name = \"movies_reviews/new_reviews/\" + file\n",
    "    with open(name, \"r\") as f:\n",
    "        contant = f.read()\n",
    "        new_rev.append(contant)\n",
    "real_score = [1,1,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7cf6070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_vec = Tvec.transform(new_rev)\n",
    "\n",
    "pred_real = clf.predict(new_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c321fd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted values are:  [0. 1. 1. 0. 0.]\n",
      "Accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"the predicted values are: \",pred_real)\n",
    "print(\"Accuracy\", accuracy_score(real_score, pred_real))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b90f0",
   "metadata": {},
   "source": [
    "The reviews I found are two negitive batman reviews, and three positive deadpool reviews. \n",
    "I used reviews that seemed to have mostly normal words in it, because if not the accuracy was very bad. \n",
    "Using these simpiler reviews, the model was able to classify 4 out 5 of the reviews correctly. This is similer to what it classified in the test data, and is pretty good.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359c509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
